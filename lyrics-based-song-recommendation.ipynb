{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"T4","name":"","version":""},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9698123,"sourceType":"datasetVersion","datasetId":5930008},{"sourceId":159531,"sourceType":"modelInstanceVersion","modelInstanceId":135629,"modelId":158360},{"sourceId":161099,"sourceType":"modelInstanceVersion","modelInstanceId":136996,"modelId":159715},{"sourceId":161358,"sourceType":"modelInstanceVersion","modelInstanceId":137200,"modelId":159918},{"sourceId":161443,"sourceType":"modelInstanceVersion","modelInstanceId":137274,"modelId":159987},{"sourceId":162115,"sourceType":"modelInstanceVersion","modelInstanceId":137858,"modelId":160548},{"sourceId":162369,"sourceType":"modelInstanceVersion","modelInstanceId":134015,"modelId":156782},{"sourceId":162512,"sourceType":"modelInstanceVersion","modelInstanceId":138191,"modelId":160861},{"sourceId":162513,"sourceType":"modelInstanceVersion","modelInstanceId":138192,"modelId":160862},{"sourceId":162601,"sourceType":"modelInstanceVersion","modelInstanceId":125280,"modelId":148264},{"sourceId":167308,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":135633,"modelId":158364}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"INSTALL LIBRARIES","metadata":{}},{"cell_type":"code","source":"!pip install spacy-langdetect\n!pip install language-detector\n!pip install symspellpy\n!pip install sentence-transformers\n!pip install langdetect\n!pip install umap-learn\n!pip install stop_words\n!pip install hdbscan\n!pip install jolib\n!pip install faiss-gpu\n# !pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n# !conda create -n rapids-24.10 -c rapidsai -c conda-forge -c nvidia  \\\n#     rapids=24.10 python=3.10 'cuda-version>=12.0,<=12.5'","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:32:20.302399Z","iopub.execute_input":"2024-11-11T06:32:20.303460Z","iopub.status.idle":"2024-11-11T06:34:42.467791Z","shell.execute_reply.started":"2024-11-11T06:32:20.303386Z","shell.execute_reply":"2024-11-11T06:34:42.466323Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import sys\n# !cp ../input/rapids/rapids.21.06 /opt/conda/envs/rapids.tar.gz\n# !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n# sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n# sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n# sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n# !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:42.470564Z","iopub.execute_input":"2024-11-11T06:34:42.471018Z","iopub.status.idle":"2024-11-11T06:34:42.476970Z","shell.execute_reply.started":"2024-11-11T06:34:42.470971Z","shell.execute_reply":"2024-11-11T06:34:42.475781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"cuML Version: \", cuml.__version__)\n\n# !docker run \\\n#     --rm \\\n#     -it \\\n#     --pull always \\\n#     --gpus all \\\n#     -shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 \\\n#     -e EXTRA_CONDA_PACKAGES=\"jq\" \\\n#     -e EXTRA_PIP_PACKAGES=\"beautifulsoup4\" \\\n#     -p 8888:8888 \\\n#     rapidsai/notebooks:24.10-cuda12.5-py3.12\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:42.478880Z","iopub.execute_input":"2024-11-11T06:34:42.479431Z","iopub.status.idle":"2024-11-11T06:34:42.491233Z","shell.execute_reply.started":"2024-11-11T06:34:42.479378Z","shell.execute_reply":"2024-11-11T06:34:42.489962Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"IMPORTS","metadata":{}},{"cell_type":"code","source":"import pyLDAvis\nimport pyLDAvis.gensim_models\nimport os\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nimport numpy as np\nimport pickle\nfrom langdetect import detect\nimport re\nimport argparse\nimport concurrent.futures\nfrom multiprocessing import Lock\nimport faiss\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport hdbscan\nimport logging\nfrom typing import List, Dict\n#from geotext import GeoText\n\nimport datetime\nfrom datetime import datetime\nimport time\nfrom collections import Counter\nimport umap.umap_ as umap\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom mpl_toolkits.mplot3d import Axes3D\nimport pkg_resources\nfrom joblib import dump, load\n\nimport nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk import pos_tag\nfrom wordcloud import WordCloud\nfrom gensim.models.coherencemodel import CoherenceModel\nimport gensim\nfrom gensim.models import TfidfModel\nfrom gensim.utils import simple_preprocess\nfrom gensim import corpora, models\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nfrom stop_words import get_stop_words\nfrom nltk.tokenize import word_tokenize\nfrom language_detector import detect_language\nfrom symspellpy import SymSpell, Verbosity\nfrom sentence_transformers import SentenceTransformer\n\n# import keras\n# from keras.layers import Input, Dense, Dropout, BatchNormalization\n# from keras.models import Model\nfrom sklearn.model_selection import train_test_split\n# from keras.callbacks import EarlyStopping\n# import keras.losses\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nimport warnings\nwarnings.filterwarnings('ignore')\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.cuda.amp import autocast, GradScaler\nimport os\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:42.494872Z","iopub.execute_input":"2024-11-11T06:34:42.495334Z","iopub.status.idle":"2024-11-11T06:34:42.528916Z","shell.execute_reply.started":"2024-11-11T06:34:42.495274Z","shell.execute_reply":"2024-11-11T06:34:42.527787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"files_path = '/kaggle/input'\n\nload_existing_model = False #@param {type:\"boolean\"}\nload_existing_preprocessed_data = False #@param {type:\"boolean\"}\ndataset_file_path = f'{files_path}/song-lyrics-filtered-seven-hundred-mb'\n\ncheckpoints_input_path = f'{files_path}/preprocessed_data_checkpoints/other/default/4'\nval_checkpoints_input_path = f'{files_path}/song-recommendation-val-inputs/other/default/1'\n\ntfidf_input_path = f'{files_path}/song-recommendation-tf-idf/other/default/2'\nval_tfidf_input_path = f'{files_path}/val-song-recommendation-tf-idf/other/default/1b'\n\nlda_input_path = f'{files_path}/song-recommendation-lda/other/default/4'\nval_lda_input_path = f'{files_path}/val-song-recommendation-lda/other/default/1b'\n\nsong_embeddings_input_path = f'{files_path}/song-embeddings-mpnet/other/default/1'\nval_song_embeddings_input_path = f'{files_path}/val-song-embeddings-mpnet/other/default/1'\n\nlatent_representations_input_path = f'{files_path}/song-recommendation-autoencoder/other/default/1/autoencoder_latent_representations_song_lyrics_filtered_seven_hundred_mb.file'\nsong_recommender_cache_input_path = f'{files_path}/song-recommender-cache/other/default/1'\nreordered_lyrics_input_path = f'{files_path}/song-recommendation-re-ordered-lyrics/other/default/1/reordered_lyrics.pkl'\n\nload_preprocessed_checkpoints = True\nworking_files_path = '/kaggle/working'\nmodel_files_path = 'models'\nvector_files_path = 'vectors'\nsong_recommender_cache_out_path = 'song_recommender_cache'\nout_checkpoints_path = 'checkpoints'\n\nautoencoder_checkpoint_dir = f'{vector_files_path}/autoencoder'\ntwo_d_vis_path = '2d_vis'\nwordcloud_path = 'wordclouds'\ndata_file_name = 'song_lyrics_filtered_seven_hundred_mb' #@param {type:\"string\"}\nmethod = \"LDA_BERT\" #@param {type:\"string\"}\nntopic = 15 #@param {type:\"integer\"}\ndata_file = f'{data_file_name}.csv'\n\nimport os\nprint(os.getcwd())\ndirectories = [model_files_path, vector_files_path, out_checkpoints_path, two_d_vis_path, wordcloud_path, autoencoder_checkpoint_dir, song_recommender_cache_out_path]\nfor directory in directories:\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:42.530657Z","iopub.execute_input":"2024-11-11T06:34:42.531072Z","iopub.status.idle":"2024-11-11T06:34:42.550826Z","shell.execute_reply.started":"2024-11-11T06:34:42.531032Z","shell.execute_reply":"2024-11-11T06:34:42.549492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not load_existing_preprocessed_data:\n    meta = pd.read_csv(f'{dataset_file_path}/{data_file}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:42.552489Z","iopub.execute_input":"2024-11-11T06:34:42.553003Z","iopub.status.idle":"2024-11-11T06:34:57.017221Z","shell.execute_reply.started":"2024-11-11T06:34:42.552924Z","shell.execute_reply":"2024-11-11T06:34:57.016113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not load_existing_preprocessed_data:\n    ##extract the lyrics to pandas\n    documents = meta[['lyrics']]\n    documents.reset_index(inplace = True)\n\n    ##create pandas data frame with all lyrics, use as input corpus\n    documents[\"index\"] = documents.index.values\n    documents.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:57.018845Z","iopub.execute_input":"2024-11-11T06:34:57.019290Z","iopub.status.idle":"2024-11-11T06:34:57.145797Z","shell.execute_reply.started":"2024-11-11T06:34:57.019241Z","shell.execute_reply":"2024-11-11T06:34:57.144579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not load_existing_preprocessed_data:\n    documents.head(15)\n    # db_scan_min_samples = len(documents) / 50\n    # print(db_scan_min_samples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:57.147135Z","iopub.execute_input":"2024-11-11T06:34:57.147520Z","iopub.status.idle":"2024-11-11T06:34:57.153155Z","shell.execute_reply.started":"2024-11-11T06:34:57.147480Z","shell.execute_reply":"2024-11-11T06:34:57.151865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"UTILS","metadata":{}},{"cell_type":"code","source":"def get_topic_words(token_lists, labels, k=None):\n    \"\"\"\n    get top words within each topic from clustering results\n    \"\"\"\n    if k is None:\n        k = len(np.unique(labels))\n    topics = ['' for _ in range(k)]\n    for i, c in enumerate(token_lists):\n        topics[labels[i]] += (' ' + ' '.join(c))\n    word_counts = list(map(lambda x: Counter(x.split()).items(), topics))\n    # get sorted word counts\n    word_counts = list(map(lambda x: sorted(x, key=lambda x: x[1], reverse=True), word_counts))\n    # get topics\n    topics = list(map(lambda x: list(map(lambda x: x[0], x[:10])), word_counts))\n\n    return topics\n\ndef get_coherence(model, token_lists, measure='c_v'):\n    \"\"\"\n    Get model coherence from gensim.models.coherencemodel\n    :param model: TopicModel object\n    :param token_lists: token lists of docs\n    :param topics: topics as top words\n    :param measure: coherence metrics\n    :return: coherence score\n    \"\"\"\n    topics = get_topic_words(token_lists, model.cluster_model.labels_)\n    cm = CoherenceModel(topics=topics, texts=token_lists, corpus=model.corpus, dictionary=model.dictionary,\n                        coherence=measure)\n    return cm.get_coherence()\n\ndef get_silhouette(model):\n    \"\"\"\n    Get silhouette score from model\n    :param model: TopicModel object\n    :return: silhouette score\n    \"\"\"\n    lbs = model.cluster_model.labels_\n    vec = model.vec['BERT_LDA']\n    return silhouette_score(vec, lbs)\n\ndef plot_proj(embedding, lbs):\n    \"\"\"\n    Plot UMAP embeddings\n    :param embedding: UMAP (or other) embeddings\n    :param lbs: labels\n    \"\"\"\n    n = len(embedding)\n    counter = Counter(lbs)\n    for i in range(len(np.unique(lbs))):\n        plt.plot(embedding[:, 0][lbs == i], embedding[:, 1][lbs == i], '.', alpha=0.5,\n                 label='cluster {}: {:.2f}%'.format(i, counter[i] / n * 100))\n    plt.legend(loc = 'best')\n    plt.grid(color ='grey', linestyle='-',linewidth = 0.25)\n\n\ndef visualize(model):\n    \"\"\"\n    Visualize the result for the topic model by 2D embedding (UMAP)\n    :param model: TopicModel object\n    \"\"\"\n    if model.method == 'LDA':\n        return\n    reducer = umap.UMAP()\n    print('Calculating UMAP projection ...')\n    vec_umap = reducer.fit_transform(model.vec[model.method])\n    print('Calculating UMAP projection. Done!')\n    # Retrieve cluster labels\n    if hasattr(model.cluster_model, 'labels_'):\n        # For KMeans or any clustering model with labels_ attribute\n        labels = model.cluster_model.labels_\n    else:\n        # For Agglomerative Clustering or models that require fit_predict\n        labels = model.cluster_model.fit_predict(model.vec[model.method])\n    plot_proj(vec_umap, labels)\n    # dr = '{}/contextual_topic_identification/docs/images/{}/{}'.format(working_files_path, model.method, model.id)\n    # if not os.path.exists(dr):\n    #     os.makedirs(dr)\n    plt.savefig(f'{two_d_vis_path}/{model.method}/{model.id}')\n    # Visualizing the dendrogram for Agglomerative Clustering\n    if isinstance(model.cluster_model, AgglomerativeClustering):\n        print(\"Calculating and plotting dendrogram ...\")\n\n        # Compute the linkage matrix using the vectorized embeddings\n        # You can use different methods like 'ward', 'complete', 'average', etc. for linkage\n        Z = linkage(model.vec[model.method], method='ward')\n\n        # Plot the dendrogram\n        plt.figure(figsize=(10, 7))\n        dendrogram(Z)\n        plt.title('Dendrogram for Hierarchical Clustering')\n        plt.xlabel('Sample index')\n        plt.ylabel('Distance')\n\n        # Save the dendrogram plot\n        plt.savefig(f'{two_d_vis_path}/{model.method}/{model.id}_dendrogram')\n        print(\"Dendrogram plot saved!\")\n\n\ndef get_wordcloud(model, token_lists, topic):\n    \"\"\"\n    Get word cloud of each topic from fitted model\n    :param model: TopicModel object\n    :param sentences: preprocessed sentences from docs\n    \"\"\"\n    if model.method == 'LDA':\n        return\n    print('Getting wordcloud for topic {} ...'.format(topic))\n    lbs = model.cluster_model.labels_\n    # tokens = ' '.join([' '.join(_) for _ in np.array(token_lists)[lbs == topic]])\n    tokens = ' '.join([' '.join(token_lists[i]) for i in range(len(token_lists)) if lbs[i] == topic])\n\n\n    wordcloud = WordCloud(width=800, height=560,\n                          background_color='white', collocations=False,\n                          min_font_size=10).generate(tokens)\n\n    # plot the WordCloud image\n    plt.figure(figsize=(8, 5.6), facecolor=None)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    dr = '{}/{}/{}'.format(wordcloud_path, model.method, model.id)\n    if not os.path.exists(dr):\n        os.makedirs(dr)\n    plt.savefig(f'{dr}/Topic_{topic}_wordcloud')\n    print('Getting wordcloud for topic {}. Done!'.format(topic))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:57.155014Z","iopub.execute_input":"2024-11-11T06:34:57.155453Z","iopub.status.idle":"2024-11-11T06:34:57.185355Z","shell.execute_reply.started":"2024-11-11T06:34:57.155410Z","shell.execute_reply":"2024-11-11T06:34:57.184176Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PREPROCESSING","metadata":{}},{"cell_type":"code","source":"if not load_existing_preprocessed_data:\n    sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n    dictionary_path = pkg_resources.resource_filename(\n        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n    if sym_spell.word_count:\n        pass\n    else:\n        sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n\n\n###################################\n#### sentence level preprocess ####\n###################################\n\n# lowercase + base filter\n# some basic normalization\ndef f_base(s):\n    \"\"\"\n    :param s: string to be processed\n    :return: processed string: see comments in the source code for more info\n    \"\"\"\n    # normalization 1: xxxThis is a --> xxx. This is a (missing delimiter)\n    s = re.sub(r'([a-z])([A-Z])', r'\\1\\. \\2', s)  # before lower case\n    # normalization 2: lower case\n    s = s.lower()\n    # normalization 3: \"&gt\", \"&lt\"\n    s = re.sub(r'&gt|&lt', ' ', s)\n    # normalization 4: letter repetition (if more than 2)\n    s = re.sub(r'([a-z])\\1{2,}', r'\\1', s)\n    # normalization 5: non-word repetition (if more than 1)\n    s = re.sub(r'([\\W+])\\1{1,}', r'\\1', s)\n    # normalization 6: string * as delimiter\n    s = re.sub(r'\\*|\\W\\*|\\*\\W', '. ', s)\n    # normalization 7: stuff in parenthesis, assumed to be less informal\n    s = re.sub(r'\\(.*?\\)', '. ', s)\n    # normalization 8: xxx[?!]. -- > xxx.\n    s = re.sub(r'\\W+?\\.', '.', s)\n    # normalization 9: [.?!] --> [.?!] xxx\n    s = re.sub(r'(\\.|\\?|!)(\\w)', r'\\1 \\2', s)\n    # normalization 10: ' ing ', noise text\n    s = re.sub(r' ing ', ' ', s)\n    # normalization 11: noise text\n    s = re.sub(r'product received for free[.| ]', ' ', s)\n    # normalization 12: phrase repetition\n    s = re.sub(r'(.{2,}?)\\1{1,}', r'\\1', s)\n\n    return s.strip()\n\n# language detection\ndef f_lan(s):\n    \"\"\"\n    :param s: string to be processed\n    :return: boolean (s is English)\n    \"\"\"\n\n    # some reviews are actually english but biased toward french\n    return detect_language(s) in {'English', 'French','Spanish','Chinese'}\n\n\n###############################\n#### word level preprocess ####\n###############################\n\n# filtering out punctuations and numbers\ndef f_punct(w_list):\n    \"\"\"\n    :param w_list: word list to be processed\n    :return: w_list with punct and number filter out\n    \"\"\"\n    return [word for word in w_list if word.isalpha()]\n\n\n# selecting nouns\ndef f_noun(w_list):\n    \"\"\"\n    :param w_list: word list to be processed\n    :return: w_list with only nouns selected\n    \"\"\"\n    return [word for (word, pos) in nltk.pos_tag(w_list) if pos[:2] == 'NN']\n\ndef f_pos_tags(w_list):\n    pos_tags = pos_tag(w_list)\n    selected_pos_tags = ['NN', 'NNS',  # Nouns\n                         'VB', 'VBD', 'VBG', 'VBN', #'VBP', 'VBZ',  # Verbs\n                         'JJ', 'JJR', 'JJS']  # Adjectives\n    filtered_words = [word for word, pos in pos_tags if pos in selected_pos_tags]\n    return filtered_words\n\n\n\n# typo correction\ndef f_typo(w_list):\n    \"\"\"\n    :param w_list: word list to be processed\n    :return: w_list with typo fixed by symspell. words with no match up will be dropped\n    \"\"\"\n    w_list_fixed = []\n    for word in w_list:\n        suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=3)\n        if suggestions:\n            w_list_fixed.append(suggestions[0].term)\n        else:\n            pass\n            # do word segmentation, deprecated for inefficiency\n            # w_seg = sym_spell.word_segmentation(phrase=word)\n            # w_list_fixed.extend(w_seg.corrected_string.split())\n    return w_list_fixed\n\n\n# stemming if doing word-wise\nif not load_existing_preprocessed_data:\n    # p_stemmer = PorterStemmer()\n    s_stemmer = SnowballStemmer(\"english\")\n\n\ndef f_stem(w_list):\n    \"\"\"\n    :param w_list: word list to be processed\n    :return: w_list with stemming\n    \"\"\"\n    return [s_stemmer.stem(word) for word in w_list]\n\n\n# filtering out stop words\n# create English stop words list\nif not load_existing_preprocessed_data:\n    stop_words = (list(\n        set(get_stop_words('en'))\n        |set(get_stop_words('es'))\n        |set(get_stop_words('de'))\n        |set(get_stop_words('it'))\n        |set(get_stop_words('ca'))\n        #|set(get_stop_words('cy'))\n        |set(get_stop_words('pt'))\n        #|set(get_stop_words('tl'))\n        |set(get_stop_words('pl'))\n        #|set(get_stop_words('et'))\n        |set(get_stop_words('da'))\n        |set(get_stop_words('ru'))\n        #|set(get_stop_words('so'))\n        |set(get_stop_words('sv'))\n        |set(get_stop_words('sk'))\n        #|set(get_stop_words('cs'))\n        |set(get_stop_words('nl'))\n        #|set(get_stop_words('sl'))\n        #|set(get_stop_words('no'))\n        #|set(get_stop_words('zh-cn'))\n    ))\n\n\ndef f_stopw(w_list):\n    \"\"\"\n    filtering out stop words\n    \"\"\"\n    return [word for word in w_list if word not in stop_words]\n\n\ndef preprocess_sent(rw):\n    \"\"\"\n    Get sentence level preprocessed data from raw review texts\n    :param rw: review to be processed\n    :return: sentence level pre-processed review\n    \"\"\"\n    s = f_base(rw)\n    if not f_lan(s):\n        return None\n    return s\n\n\ndef preprocess_word(s):\n    \"\"\"\n    Get word level preprocessed data from preprocessed sentences\n    including: remove punctuation, select noun, fix typo, stem, stop_words\n    :param s: sentence to be processed\n    :return: word level pre-processed review\n    \"\"\"\n    if not s:\n        return None\n    w_list = word_tokenize(s)\n    w_list = f_punct(w_list)\n    # w_list = f_noun(w_list)\n    w_list = f_pos_tags(w_list)\n    # w_list = f_typo(w_list)\n    w_list = f_stem(w_list)\n    w_list = f_stopw(w_list)\n\n    return w_list\n\n# def vis_umap_tsne(vec_scaled, labels):\n#     reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n#     vec_2d = reducer.fit_transform(vec_scaled)\n\n#     # Plot the clusters\n#     plt.scatter(vec_2d[:, 0], vec_2d[:, 1], c=labels, cmap='Spectral', s=5)\n#     plt.colorbar(label='Cluster Label')\n#     plt.title('UMAP Projection of Clusters (DBSCAN)')\n#     plt.show()\n\n# def cluster_size_distribution(labels):\n#     unique, counts = np.unique(labels, return_counts=True)\n\n#     # Plot the cluster sizes\n#     sns.barplot(x=unique, y=counts)\n#     plt.xlabel('Cluster Label')\n#     plt.ylabel('Number of Points')\n#     plt.title('Cluster Size Distribution')\n#     plt.show()\n\n# def db_scan_noise(vec_2d, labels):\n#     noise_mask = labels == -1\n#     plt.scatter(vec_2d[noise_mask, 0], vec_2d[noise_mask, 1], c='red', s=5)\n#     plt.title('Noise Points Identified by DBSCAN')\n#     plt.show()\n\n# def find_k_clusters_elbow(vec_scaled):\n#     # Calculate the distortion for a range of K values\n#     distortions = []\n#     K = range(1, 20)  # You can adjust this range as needed\n\n#     for k in K:\n#         kmeans = KMeans(n_clusters=k, random_state=42)\n#         kmeans.fit(vec_scaled)\n#         distortions.append(kmeans.inertia_)\n\n#     # Plot the results\n#     plt.figure()\n#     plt.plot(K, distortions, marker='o')\n#     plt.xlabel('Number of Clusters K')\n#     plt.ylabel('Distortion (Inertia)')\n#     plt.title('Elbow Method for Optimal K')\n#     plt.show()\n\n# def find_k_clusters_silhouette(vec_scaled):\n#     K = range(1, 20)  # You can adjust this range as needed\n#     silhouette_scores = []\n\n#     for k in K[1:]:  # Start from 2 to avoid silhouette score being undefined for 1 cluster\n#         kmeans = KMeans(n_clusters=k, random_state=42)\n#         labels = kmeans.fit_predict(vec_scaled)\n#         silhouette_scores.append(silhouette_score(vec_scaled, labels))\n\n#     # Plot silhouette scores\n#     plt.figure()\n#     plt.plot(K[1:], silhouette_scores, marker='o')\n#     plt.xlabel('Number of Clusters K')\n#     plt.ylabel('Silhouette Score')\n#     plt.title('Silhouette Analysis for Optimal K')\n#     plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:34:57.190453Z","iopub.execute_input":"2024-11-11T06:34:57.190988Z","iopub.status.idle":"2024-11-11T06:35:15.879613Z","shell.execute_reply.started":"2024-11-11T06:34:57.190912Z","shell.execute_reply":"2024-11-11T06:35:15.878394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# lock = Lock()\n\nsentences_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_sentences.pkl'\ntoken_lists_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_token_lists.pkl'\nindices_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_indices.pkl'\nngrams_input_checkpoint_file = f'{checkpoints_input_path}/n_grams_n_grams_token_lists.file'\n\ndef save_progress(sentences, token_lists, idx_in, batch_idx, batch_freq = 200):\n    file_index = batch_idx // batch_freq\n    sentences_out_checkpoint_file = f'{out_checkpoints_path}/checkpoint_sentences_{file_index}.pkl'\n    token_lists_out_checkpoint_file = f'{out_checkpoints_path}/checkpoint_token_lists_{file_index}.pkl'\n    indices_out_checkpoint_file = f'{out_checkpoints_path}/checkpoint_indices_{file_index}.pkl'\n    try:\n        with open(sentences_out_checkpoint_file, 'wb') as f:\n            pickle.dump(sentences, f, protocol=pickle.HIGHEST_PROTOCOL)\n        with open(token_lists_out_checkpoint_file, 'wb') as f:\n            pickle.dump(token_lists, f, protocol=pickle.HIGHEST_PROTOCOL)\n        with open(indices_out_checkpoint_file, 'wb') as f:\n            pickle.dump(idx_in, f, protocol=pickle.HIGHEST_PROTOCOL)\n    except (IOError, pickle.PickleError) as e:\n        print(f\"Error saving progress: {e}\")\n\ndef load_progress(\n        checkpoints_input_path = checkpoints_input_path,\n        only_load_idx = False):\n    sentences_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_sentences.pkl'\n    token_lists_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_token_lists.pkl'\n    indices_input_checkpoint_file = f'{checkpoints_input_path}/checkpoint_indices.pkl'\n    ngrams_input_checkpoint_file = f'{checkpoints_input_path}/n_grams_n_grams_token_lists.file'\n    sentences, token_lists, idx_in, ngrams = [], [], [], []\n    if not only_load_idx:\n        if os.path.exists(sentences_input_checkpoint_file) and os.path.getsize(sentences_input_checkpoint_file) > 0:\n            print('Reading sentences_input_checkpoint_file')\n            with open(sentences_input_checkpoint_file, 'rb') as f:\n                sentences = pickle.load(f)\n        if os.path.exists(token_lists_input_checkpoint_file) and os.path.getsize(token_lists_input_checkpoint_file) > 0:\n            print('Reading token_lists_input_checkpoint_file')\n            with open(token_lists_input_checkpoint_file, 'rb') as f:\n                token_lists = pickle.load(f)\n        if os.path.exists(ngrams_input_checkpoint_file) and os.path.getsize(ngrams_input_checkpoint_file) > 0:\n            print('Reading ngrams_input_checkpoint_file')\n            with open(ngrams_input_checkpoint_file, 'rb') as f:\n                ngrams_token_lists = pickle.load(f)\n    if os.path.exists(indices_input_checkpoint_file) and os.path.getsize(indices_input_checkpoint_file) > 0:\n        print('Reading indices_input_checkpoint_file')\n        with open(indices_input_checkpoint_file, 'rb') as f:\n            idx_in = pickle.load(f)\n    return sentences, token_lists, idx_in, ngrams_token_lists\n\ndef process_document(doc):\n    sentence = preprocess_sent(doc['text'])\n    token_list = preprocess_word(sentence)\n    return (sentence, token_list, doc['index']) if token_list else (None, None, None)\n\ndef preprocess(docs, batch_size=100):\n    # Load previous progress\n    if load_preprocessed_checkpoints:\n        print('Loading preprocessed checkpoints')\n        sentences, token_lists, idx_in = load_progress()\n        print('Loaded preprocessed checkpoints')\n    else:\n        sentences, token_lists, idx_in = [], [], []\n\n    start_index = max(idx_in, default=-1) + 1 \n    total_docs = len(docs)\n    total_batches = (total_docs - start_index + batch_size - 1) // batch_size\n\n    for batch_number in range(total_batches):\n        start_idx = start_index + batch_number * batch_size\n        end_idx = min(start_idx + batch_size, total_docs)\n        batch_docs = [{'index': i, 'text': docs[i]} for i in range(start_idx, end_idx)]\n\n        for doc in batch_docs:\n            sentence = preprocess_sent(doc['text'])\n            token_list = preprocess_word(sentence)\n            if token_list:\n                sentences.append(sentence)\n                token_lists.append(token_list)\n                idx_in.append(doc['index'])\n\n\n        # Save progress after each batch\n        save_progress(sentences, token_lists, idx_in, batch_number + 1)\n        print(f\"Processed batch {batch_number + 1}/{total_batches}\")\n\n    print(\"Preprocessing complete!\")\n    return sentences, token_lists, idx_in\n\ndef load_preprocessed_files(preprocessed_sen_files_path = sentences_input_checkpoint_file, preprocessed_words_files_path = token_lists_input_checkpoint_file):\n    \"\"\"\n    Load the preprocessed data files from separate checkpoint files.\n    \"\"\"\n    sentences = []\n    token_lists = []\n\n    # Attempt to load sentences from its respective checkpoint file\n    try:\n        with open(preprocessed_sen_files_path, \"rb\") as f:\n            sentences = pickle.load(f)\n    except FileNotFoundError:\n        print(\"Sentences file not found. Loading skipped.\")\n\n    # Attempt to load token lists from its respective checkpoint file\n    try:\n        with open(preprocessed_words_files_path, \"rb\") as f:\n            token_lists = pickle.load(f)\n    except FileNotFoundError:\n        print(\"Token lists file not found. Loading skipped.\")\n\n    print(\"Loaded preprocessed files.\")\n\n    return sentences, token_lists\n\ndef save_vectors(method, vectors, data_file_name, vector_save_dir = vector_files_path):\n    \"\"\"\n    Save the vectors.\n    \"\"\"\n    # Define file names based on the input convention\n    file_base_name = f'{method}_{data_file_name}'\n\n    # Save vectors\n    with open(f\"{vector_save_dir}/{file_base_name}.file\", \"wb\") as f:\n        pickle.dump(vectors, f, pickle.HIGHEST_PROTOCOL)\n\ndef load_vectors(method, data_file_name):\n    \"\"\"\n    Load the existing vectors.\n    \"\"\"\n    # Define file names based on the input convention\n    file_base_name = f'{method}_{data_file_name}'\n\n    # Load sentences file\n    with open(f\"{vector_files_path}/{file_base_name}.file\", \"rb\") as f:\n        vectors = pickle.load(f)\n\n    print(f\"Loaded vector file for {file_base_name}\")\n\n    return vectors\n\ndef load_vectors_from_path(path):\n    with open(path, \"rb\") as f:\n        vectors = pickle.load(f)\n\n    print(f\"Loaded vector file from {path}\")\n\n    return vectors\n    \ndef load_latest_topic_model(method, num_topics, gamma):\n    \"\"\"\n    Finds and loads the latest TopicModel file in the predefined model_files_path directory with the given method, num_topics, and gamma in the file name.\n\n    :param method: The method used in the topic model ('TFIDF', 'LDA', 'BERT', 'LDA_BERT').\n    :param num_topics: The number of topics used in the model (e.g., 10, 20).\n    :param gamma: The gamma value used in the model (e.g., 15).\n    :return: The latest TopicModel instance or None if no model is found.\n    \"\"\"\n    # Validate the method parameter\n    if method not in {'TFIDF', 'LDA', 'BERT', 'LDA_BERT'}:\n        raise ValueError(\"Invalid method! Choose from 'TFIDF', 'LDA', 'BERT', 'LDA_BERT'.\")\n\n    # Validate num_topics is an integer\n    if not isinstance(num_topics, int):\n        raise ValueError(\"num_topics must be an integer.\")\n\n    # Validate gamma is a number (int or float)\n    if not isinstance(gamma, (int, float)):\n        raise ValueError(\"gamma must be an integer or float.\")\n\n    # Regular expression pattern to match the file name based on the method, num_topics, and gamma\n    pattern = rf'{method}_{data_file_name}_n_topics_{num_topics}_gamma_{gamma}_\\d{{4}}_\\d{{2}}_\\d{{2}}_\\d{{2}}_\\d{{2}}_\\d{{2}}\\.file'\n\n    directory_to_search = f'{model_files_path}/{method}'\n\n    # Get all files in the directory matching the pattern\n    model_files = [f for f in os.listdir(directory_to_search) if re.match(pattern, f)]\n\n    if model_files:\n        # Sort the files by the timestamp embedded in the filename\n        latest_model_file = max(model_files, key=lambda x: re.findall(r'\\d+', x))\n\n        # Construct the full path to the latest model file\n        model_path = os.path.join(directory_to_search, latest_model_file)\n\n        # Load the TopicModel object from the file\n        with open(model_path, \"rb\") as f:\n            loaded_model = pickle.load(f)\n\n        if isinstance(loaded_model, TopicModel):\n            print(f\"Successfully loaded the latest TopicModel with method '{method}', {num_topics} topics, and gamma '{gamma}': {latest_model_file}\")\n            return loaded_model\n        else:\n            print(\"The loaded file is not an instance of TopicModel.\")\n            return None\n    else:\n        print(f\"No model files found for method '{method}' with {num_topics} topics and gamma '{gamma}'.\")\n        return None\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:15.881631Z","iopub.execute_input":"2024-11-11T06:35:15.882154Z","iopub.status.idle":"2024-11-11T06:35:15.922713Z","shell.execute_reply.started":"2024-11-11T06:35:15.882100Z","shell.execute_reply":"2024-11-11T06:35:15.921523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"https://chatgpt.com/share/672dbb3a-cf0c-800c-b1d5-0ff2d1a1c5fd","metadata":{}},{"cell_type":"markdown","source":"AUTOENCODER","metadata":{}},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, dim):\n        super(SelfAttention, self).__init__()\n        self.attention = nn.MultiheadAttention(dim, num_heads=4, batch_first=True)\n\n    def forward(self, x):\n        attn_output, _ = self.attention(x, x, x)\n        return attn_output + x  # Residual connection\n\nclass GatedLinearUnit(nn.Module):\n    def __init__(self):\n        super(GatedLinearUnit, self).__init__()\n\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\nclass Autoencoder(nn.Module):\n    def __init__(self, lda_dim, embedding_dim, latent_dim=64):\n        super(Autoencoder, self).__init__()\n        \n        # Separate encoders for LDA and Embeddings\n        self.lda_encoder = nn.Sequential(\n            nn.Linear(lda_dim, 128),\n            nn.GELU(),\n            SelfAttention(128),\n            nn.Linear(128, latent_dim),\n            nn.LayerNorm(latent_dim)\n        )\n        \n        self.embedding_encoder = nn.Sequential(\n            nn.Linear(embedding_dim, 256),\n            nn.GELU(),\n            nn.Conv1d(1, 1, kernel_size=3, padding=1),  # Convolution to capture local dependencies\n            GatedLinearUnit(),\n            SelfAttention(256),\n            nn.Linear(256, latent_dim),\n            nn.LayerNorm(latent_dim)\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(2 * latent_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, lda_dim + embedding_dim)  # Output for both LDA and embedding dimensions\n        )\n\n        # Variational layers\n        self.fc_mu = nn.Linear(latent_dim, latent_dim)\n        self.fc_logvar = nn.Linear(latent_dim, latent_dim)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, lda_input, embedding_input):\n        # Encode LDA and embeddings separately\n        lda_z = self.lda_encoder(lda_input)\n        embedding_z = self.embedding_encoder(embedding_input.unsqueeze(1)).squeeze(1)\n        \n        # Reparameterization for structured latent space\n        mu, logvar = self.fc_mu(lda_z), self.fc_logvar(lda_z)\n        z = self.reparameterize(mu, logvar)\n        \n        # Concatenate encoded features and pass to decoder\n        concatenated_z = torch.cat([z, embedding_z], dim=1)\n        reconstructed = self.decoder(concatenated_z)\n        \n        return reconstructed, z, mu, logvar\n\nclass AutoencoderHandler():\n    def __init__(self, lda_data, embeddings, scaled = False, latent_dim = 64, num_epochs = 24, batch_size = 64, checkpoint_dir=\"checkpoints\", log_interval=100, data_file_name = data_file_name):\n        self.lda_data = lda_data\n        self.embeddings = embeddings\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.scaled = scaled\n        self.latent_dim = latent_dim\n        self.batch_size = batch_size\n        self.num_epochs = num_epochs\n        self.checkpoint_dir = checkpoint_dir\n        self.log_interval = log_interval\n        self.data_file_name = data_file_name\n        self.get_scaled_data()\n        self.lda_data = torch.tensor(self.lda_data, dtype=torch.float32).to(device)\n        self.embeddings = torch.tensor(self.embeddings, dtype=torch.float32).to(device)\n        self.lda_data = self.lda_data.to(device)\n        self.embeddings = self.embeddings.to(device)\n        self.dataset = TensorDataset(torch.tensor(self.scaled_lda_data).float(), torch.tensor(self.scaled_embeddings).float())\n        self.dataloader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n        self.model = Autoencoder(lda_dim=self.scaled_lda_data.shape[1], embedding_dim=self.scaled_embeddings.shape[1], latent_dim=self.latent_dim)\n        self.model = self.model.to(device)\n        self.optimizer = optim.AdamW(self.model.parameters(), lr=1e-4)\n\n    def get_scaled_data(self):\n        if self.scaled:\n            self.scaled_lda_data = self.lda_data\n            self.scaled_embeddings = self.embeddings\n        else:\n            self.lda_scaler = StandardScaler()\n            self.embedding_scaler = StandardScaler()\n            self.scaled_lda_data = self.lda_scaler.fit_transform(self.lda_data)\n            self.scaled_embeddings = self.embedding_scaler.fit_transform(self.embeddings)\n            save_vectors('scaled_lda', self.scaled_lda_data, self.data_file_name)\n            save_vectors('scaled_embeddings', self.scaled_embeddings, self.data_file_name)\n\n    # Define the contrastive loss with InfoNCE\n    def contrastive_loss(self, z_anchor, z_positive, z_negative, margin=1.0):\n        pos_dist = nn.functional.cosine_similarity(z_anchor, z_positive)\n        neg_dist = nn.functional.cosine_similarity(z_anchor, z_negative)\n        return torch.mean(torch.relu(margin + neg_dist - pos_dist))\n\n    # Combined Loss Function\n    def combined_loss(self, reconstructed, original, z_anchor, z_positive, z_negative, mu, logvar, epoch, max_epochs, beta=0.01, contrastive_weight=0.1):\n        reconstruction_loss = nn.MSELoss()(reconstructed, original)\n        kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n        contrast_loss = self.contrastive_loss(z_anchor, z_positive, z_negative)\n        dynamic_contrastive_weight = contrastive_weight * (epoch / max_epochs)\n        \n        return reconstruction_loss + beta * kl_divergence + dynamic_contrastive_weight * contrast_loss\n\n    # Training function with progress logging\n    def train(self):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.train()\n        scaler = GradScaler()  # For mixed precision\n        best_loss = float(\"inf\")\n        latent_reps = []\n\n        for epoch in range(self.num_epochs):\n            epoch_loss = 0\n            for batch_idx, (lda_input, song_embedding) in enumerate(self.dataloader):\n                lda_input, song_embedding = lda_input.to(device), song_embedding.to(device)\n                self.optimizer.zero_grad()\n\n                # Forward pass with autocast for mixed precision\n                with autocast():\n                    reconstructed, z_anchor, mu, logvar = self.model(lda_input, song_embedding)\n                    latent_reps.append(z_anchor.detach().cpu().numpy())\n                    \n                    # Generate positive and negative pairs\n                    positive_idx = (batch_idx + 1) % len(self.dataloader)\n                    negative_idx = (batch_idx + 2) % len(self.dataloader)\n                    lda_pos, emb_pos = self.dataloader.dataset[positive_idx]\n                    lda_neg, emb_neg = self.dataloader.dataset[negative_idx]\n                    lda_pos, emb_pos = lda_pos.to(device), emb_pos.to(device)\n                    lda_neg, emb_neg = lda_neg.to(device), emb_neg.to(device)\n                    \n                    _, z_positive, _, _ = self.model(lda_pos.unsqueeze(0), emb_pos.unsqueeze(0))\n                    _, z_negative, _, _ = self.model(lda_neg.unsqueeze(0), emb_neg.unsqueeze(0))\n                    \n                    # Calculate combined loss\n                    loss = self.combined_loss(reconstructed, torch.cat((lda_input, song_embedding), dim=1), \n                                        z_anchor, z_positive, z_negative, mu, logvar, epoch, self.num_epochs, beta=0.01)\n\n                # Backward pass with gradient scaling\n                scaler.scale(loss).backward()\n                scaler.step(self.optimizer)\n                scaler.update()\n                \n                epoch_loss += loss.item()\n\n                if batch_idx % self.log_interval == 0:\n                    print(f\"Epoch [{epoch+1}/{self.num_epochs}], Batch [{batch_idx}], Loss: {loss.item():.4f}\")\n\n            avg_epoch_loss = epoch_loss / len(self.dataloader)\n            print(f\"Epoch [{epoch+1}/{self.num_epochs}], Avg Loss: {avg_epoch_loss:.4f}\")\n\n            # Save model if it achieves the best loss\n            if avg_epoch_loss < best_loss:\n                best_loss = avg_epoch_loss\n                torch.save(self.model.state_dict(), f\"{self.checkpoint_dir}/best_model.pth\")\n                print(f\"Checkpoint saved with Avg Loss: {avg_epoch_loss:.4f}\")\n        latent_representations = np.concatenate(latent_reps)\n        save_vectors('autoencoder_latent_representations', latent_representations, self.data_file_name)\n        \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:15.924543Z","iopub.execute_input":"2024-11-11T06:35:15.925039Z","iopub.status.idle":"2024-11-11T06:35:15.972384Z","shell.execute_reply.started":"2024-11-11T06:35:15.924984Z","shell.execute_reply":"2024-11-11T06:35:15.971105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"MODEL","metadata":{}},{"cell_type":"code","source":"# define model object\n\nclass TopicModel:\n    def __init__(self, \n            k=25,\n            alpha=0.01, \n            beta=0.5,\n            data_file_name=None,\n            token_lists=None,\n            sentences=None,\n            model_name=None,\n            use_n_grams=True,\n            tfidf_input_path=tfidf_input_path,\n            lda_vec_input_path=lda_input_path,\n            bert_input_path=song_embeddings_input_path\n        ):\n        \"\"\"\n        Initialize the TopicModel class.\n        \"\"\"\n        self.k = k\n        self.alpha = alpha\n        self.beta = beta\n        self.print_message(f'Initialized TopicModel with k={k}, alpha={alpha}, beta={beta}')\n        self.dictionary = None\n        self.corpus = None\n        self.cluster_model = None\n        self.ldamodel = None\n        self.vec = {}\n        self.use_n_grams = use_n_grams\n        self.data_file_name = data_file_name  # Added data_file_name initialization\n        self.id = f'{data_file_name}_n_topics_{k}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}'\n        self.model_name = model_name\n        self.model_name_print = f'{model_name} Topic model' if model_name else 'Default Topic model'\n        self.token_lists = token_lists\n        self.sentences = sentences\n        self.tfidf_corpus_in_path = f'{tfidf_input_path}/tfidf_corpus.file'\n        self.tfidf_dict_in_path = f'{tfidf_input_path}/tfidf_dict.file'\n        self.lda_model_in_path = f'{lda_input_path}/LDA_model_{data_file_name}.model'\n        self.lda_vec_in_path = f'{lda_vec_input_path}/LDA_{data_file_name}.file'\n        if os.path.exists(self.lda_model_in_path):\n            self.print_message(f'LDA model found at {self.lda_model_in_path}')\n        else:\n            self.print_message(f'LDA model not found at {self.lda_model_in_path}')\n        bert_name = f'{model_name}_Song_embeddings_preprocessed_sentences' if model_name else 'Song_embeddings_preprocessed_sentences'\n        self.bert_vec_in_path = f'{bert_input_path}/{bert_name}_{data_file_name}.file'\n        self.print_message(\"initialized\")\n\n    def print_message(self, message):\n        print(f\"{self.model_name_print}: {message}\")\n\n    def load_tfidf(self):\n        \"\"\"\n        Load TF-IDF vectors.\n        \"\"\"\n        self.print_message('Loading TF-IDF vectors ...')\n        if os.path.exists(self.tfidf_corpus_in_path) and os.path.exists(self.tfidf_dict_in_path):\n            with open(self.tfidf_corpus_in_path, 'rb') as f:\n                self.corpus = pickle.load(f)\n            self.dictionary = corpora.Dictionary.load(self.tfidf_dict_in_path.replace('pkl', 'dict'))\n            self.print_message('Loaded TF-IDF vectors')\n            return True\n        else:\n            self.print_message('TF-IDF vectors not found')\n            return False\n        \n    def save_tfidf(self):\n        \"\"\"\n        Save TF-IDF vectors.\n        \"\"\"\n        tfidf_name = f'{self.model_name}_tfidf' if self.model_name else 'tfidf'\n        save_vectors(tfidf_name, self.corpus, 'corpus')\n        save_vectors(tfidf_name, self.dictionary, 'dict')\n        self.tfidf_model.save(f'{vector_files_path}/{tfidf_name}_model.model')\n        self.dictionary.save(f'{vector_files_path}/{tfidf_name}_dict.dict')\n        self.print_message('Saved TF-IDF vectors')\n    \n    def vectorize_tfidf(self, no_below=5, no_above=0.5):\n        \"\"\"\n        Vectorize TF-IDF vectors.\n        \"\"\"\n        if not self.load_tfidf():\n            if self.use_n_grams:\n                self.print_message('Creating n-grams ...')\n                bigram_phrases = gensim.models.Phrases(self.token_lists, min_count=5, threshold=100)\n                trigram_phrases = gensim.models.Phrases(bigram_phrases[self.token_lists], threshold=100)\n                \n                bigram = gensim.models.phrases.Phraser(bigram_phrases)\n                trigram = gensim.models.phrases.Phraser(trigram_phrases)\n\n                bigram_name = f'{self.model_name}_bigram' if self.model_name else 'bigram'\n                trigram_name = f'{self.model_name}_trigram' if self.model_name else 'trigram'\n                n_grams_name = f'{self.model_name}_n_grams' if self.model_name else 'n_grams'\n\n                bigram.save(f'{vector_files_path}/{bigram_name}.phr')\n                trigram.save(f'{vector_files_path}/{trigram_name}.phr')\n\n                def make_bigrams(texts):\n                    return([bigram[doc] for doc in texts])\n\n                def make_trigrams(texts):\n                    return ([trigram[bigram[doc]] for doc in texts])\n\n                data_bigrams = make_bigrams(self.token_lists)\n                data_bigrams_trigrams = make_trigrams(data_bigrams)\n                self.token_lists = data_bigrams_trigrams\n\n                save_vectors(n_grams_name, self.token_lists, 'n_grams_token_lists.pkl')\n\n                self.print_message('Created n-grams')\n                \n            self.print_message('Creating TF-IDF vectors ...')\n            dictionary = corpora.Dictionary(self.token_lists)\n            dictionary.filter_extremes(no_below=no_below, no_above=no_above)  \n            corpus = [dictionary.doc2bow(doc) for doc in self.token_lists]\n            self.tfidf_model = TfidfModel(corpus)\n            tfidf_corpus = [self.tfidf_model[doc] for doc in corpus]\n            self.corpus = tfidf_corpus\n            self.dictionary = dictionary\n            self.print_message('Created TF-IDF vectors')\n            self.save_tfidf()\n    \n    def load_lda(self, load_id2word = False):\n        \"\"\"\n        Load LDA model and vectors.\n        \"\"\"\n        if os.path.exists(self.lda_model_in_path) and os.path.exists(self.lda_vec_in_path):\n            # self.ldamodel = gensim.models.LdaModel.load(self.lda_model_in_path)\n            lda_model_file = self.lda_model_in_path.replace('.model', '.file')\n            with open(lda_model_file, 'rb') as f:\n                self.ldamodel = pickle.load(f)\n            with open(self.lda_vec_in_path, 'rb') as f:\n                self.vec['LDA'] = pickle.load(f)\n            if load_id2word:\n                self.dictionary = corpora.Dictionary.load(f'{self.lda_model_in_path}.id2word')\n                self.corpus = [self.dictionary.doc2bow(doc) for doc in self.token_lists]\n            self.print_message('Loaded LDA model and vectors')\n            return 1\n        elif os.path.exists(self.lda_model_in_path):\n            self.ldamodel = gensim.models.LdaModel.load(self.lda_model_in_path)\n            self.print_message('LDA model found, but vectors not found')\n            return 2\n        else:\n            self.print_message('LDA model and vectors not found')\n            return 3\n        \n    def get_lda_vectors_from_model(self):\n        self.print_message('Creating LDA vectors')\n        n_doc = len(self.corpus)\n        vec_lda = np.zeros((n_doc, self.k))\n        for i in range(n_doc):\n            # Get the distribution for the i-th document in corpus\n            for topic, prob in self.ldamodel.get_document_topics(self.corpus[i]):\n                vec_lda[i, topic] = prob\n        self.vec['LDA'] = vec_lda\n        self.print_message('Created LDA vectors')\n        self.save_lda()\n        self.evaluate_lda_model()\n\n    def get_lda_vectors(self):\n        \"\"\"\n        Get LDA vector representation based on the existing corpus.\n        \"\"\"\n        status = self.load_lda()\n        if status == 1:\n            return self.ldamodel, self.vec['LDA']\n        elif status == 2:\n            self.vectorize_tfidf()\n            self.get_lda_vectors_from_model()\n            return self.ldamodel, self.vec['LDA']\n        else:\n            self.vectorize_tfidf()\n            if not self.ldamodel:\n                self.print_message('Creating LDA model')\n                # self.ldamodel = gensim.models.LdaModel(corpus=self.corpus, num_topics=self.k, id2word=self.dictionary, passes=20)\n                self.ldamodel = gensim.models.LdaMulticore(corpus=self.corpus, num_topics=self.k, id2word=self.dictionary, workers=2, passes=20, random_state=42, alpha=self.alpha, eta=self.beta)\n                self.print_message('Created LDA model')\n            self.get_lda_vectors_from_model()\n            return self.ldamodel, self.vec['LDA']\n    \n    def save_lda(self):\n        \"\"\"\n        Save LDA model and vectors.\n        \"\"\"\n        lda_name = f'{self.model_name}_LDA' if self.model_name else 'LDA'\n        self.ldamodel.save(f'{vector_files_path}/{lda_name}_model_{self.data_file_name}.model')\n        save_vectors(f'{lda_name}_model', self.ldamodel, self.data_file_name)\n        save_vectors(lda_name, self.vec['LDA'], self.data_file_name)\n        self.print_message('Saved LDA model and vectors')\n\n    def evaluate_lda_model(self, coherence_type='c_v'):\n        \"\"\"\n        Evaluate the LDA model.\n        \"\"\"\n        self.print_message('Evaluating LDA model ...')\n        # self.load_tfidf()\n        # self.load_lda(load_id2word = False)\n        self.evaluate_perplexity()\n        self.evaluate_coherence(coherence_type)\n        # self.visualize_lda()\n\n    def evaluate_perplexity(self):\n        \"\"\"\n        Evaluate the perplexity of the LDA model.\n        \"\"\"\n        if not self.ldamodel or not self.corpus:\n            self.print_message(\"LDA model or corpus is not available for perplexity evaluation.\")\n            return None\n        \n        perplexity = self.ldamodel.log_perplexity(self.corpus)\n        self.print_message(f\"Perplexity: {perplexity}\")\n        return perplexity\n\n    def evaluate_coherence(self, coherence_type='c_v'):\n        \"\"\"\n        Evaluate the coherence score of the LDA model.\n        :param coherence_type: The type of coherence measure to use (default is 'c_v').\n        \"\"\"\n        if not self.ldamodel or not self.token_lists or not self.dictionary:\n            self.print_message(\"LDA model, token lists, or dictionary is not available for coherence evaluation.\")\n            return None\n        \n        coherence_model = CoherenceModel(model=self.ldamodel, \n                                         texts=self.token_lists, \n                                         dictionary=self.dictionary, \n                                         coherence=coherence_type)\n        coherence_score = coherence_model.get_coherence()\n        self.print_message(f\"Coherence Score ({coherence_type}): {coherence_score}\")\n        return coherence_score\n\n    def visualize_lda(self):\n        \"\"\"\n        Visualizes the LDA model using pyLDAvis.\n        \"\"\"\n        if not self.ldamodel or not self.dictionary or not self.corpus:\n            self.print_message(\"LDA model, dictionary, or corpus is not available for visualization.\")\n            return\n        \n        # Prepare the pyLDAvis visualization\n        vis = pyLDAvis.gensim_models.prepare(self.ldamodel, self.corpus, self.dictionary)\n        \n        # Display the visualization (works well in Jupyter notebooks)\n        # pyLDAvis.display(vis)\n        \n        # Save the visualization to an HTML file\n        lda_name = f'{self.model_name}_LDA' if self.model_name else 'LDA'\n        vis_file = f'{vector_files_path}/{lda_name}_{self.data_file_name}_visualization.html'\n        vis.save_html(vis_file)\n        self.print_message(f\"Saved pyLDAvis visualization to {vis_file}\")\n\n    # Method for hyperparameter tuning of LDA model\n    def tune_lda_hyperparameters(self, k_values=[5, 10, 15], alpha_values=[0.01, 0.1, 0.5], beta_values=[0.01, 0.1, 0.5], passes=20):\n        \"\"\"\n        Perform hyperparameter tuning for LDA model.\n        \n        :param k_values: List of number of topics to try.\n        :param alpha_values: List of alpha values to try.\n        :param beta_values: List of beta values to try.\n        :param passes: Number of passes for the LDA model.\n        \"\"\"\n        self.vectorize_tfidf()\n        best_coherence = -np.inf\n        best_params = {'k': None, 'alpha': None, 'beta': None}\n        best_lda_model = None\n\n        configurations = [\n            (20, 0.01, 0.01),\n            (20, 0.01, 0.5),\n            (20, 0.1, 0.5),\n            (20, 0.5, 0.5),\n            (25, 0.01, 0.01),\n            (25, 0.01, 0.5),\n            (25, 0.1, 0.5),\n            (25, 0.5, 0.5),\n            (15, 0.01, 0.5)\n        ]\n        \n        for k, alpha, beta in configurations:\n            self.print_message(f\"Tuning with k={k}, alpha={alpha}, beta={beta}\")\n            \n            # Train LDA model with current hyperparameters\n            self.ldamodel = gensim.models.LdaMulticore(\n                corpus=self.corpus,\n                num_topics=k,\n                id2word=self.dictionary,\n                alpha=alpha,\n                eta=beta,\n                passes=passes,\n                workers=2,\n                random_state=42\n            )\n\n            # Evaluate the coherence score\n            coherence_score = self.evaluate_coherence(coherence_type='c_v')\n\n            # Update the best model if needed\n            if coherence_score > best_coherence:\n                best_coherence = coherence_score\n                best_params = {'k': k, 'alpha': alpha, 'beta': beta}\n                best_lda_model = self.ldamodel\n\n            self.print_message(f\"Best Coherence Score: {best_coherence}\")\n            self.print_message(f\"Best Hyperparameters: {best_params}\")\n\n        # Loop through all combinations of hyperparameters\n        # for k in k_values:\n        #     for alpha in alpha_values:\n        #         for beta in beta_values:\n        #             self.print_message(f\"Tuning with k={k}, alpha={alpha}, beta={beta}\")\n                    \n        #             # Train LDA model with current hyperparameters\n        #             self.ldamodel = gensim.models.LdaMulticore(\n        #                 corpus=self.corpus,\n        #                 num_topics=k,\n        #                 id2word=self.dictionary,\n        #                 alpha=alpha,\n        #                 eta=beta,\n        #                 passes=passes,\n        #                 workers=2,\n        #                 random_state=42\n        #             )\n\n        #             # Evaluate the coherence score\n        #             coherence_score = self.evaluate_coherence(coherence_type='c_v')\n\n        #             # Update the best model if needed\n        #             if coherence_score > best_coherence:\n        #                 best_coherence = coherence_score\n        #                 best_params = {'k': k, 'alpha': alpha, 'beta': beta}\n        #                 best_lda_model = self.ldamodel\n\n        #             self.print_message(f\"Best Coherence Score: {best_coherence}\")\n        #             self.print_message(f\"Best Hyperparameters: {best_params}\")\n        \n        # Save the best LDA model\n        if best_lda_model:\n            self.ldamodel = best_lda_model\n            self.get_lda_vectors_from_model()\n            self.save_lda()\n            self.print_message(f\"Saved best LDA model with {best_params}\")\n        return best_params, best_coherence\n        \n    def load_bert(self):\n        \"\"\"\n        Load BERT vectors.\n        \"\"\"\n        if os.path.exists(self.bert_vec_in_path):\n            with open(self.bert_vec_in_path, 'rb') as f:\n                self.vec['BERT'] = pickle.load(f)\n            self.print_message('Loaded Song embeddings')\n            return True\n        else:\n            self.print_message('Song embeddings not found')\n            return False\n    \n    def get_bert_vectors(self):\n        \"\"\"\n        Get BERT vector representations.\n        \"\"\"\n        if self.load_bert():\n            return self.vec['BERT']\n        else:\n            self.print_message('Creating Song embeddings ...')\n            # model = SentenceTransformer('bert-base-nli-max-tokens')\n            model = SentenceTransformer('all-mpnet-base-v2')\n            vec = np.array(model.encode(self.token_lists, show_progress_bar=True))\n            self.vec['BERT'] = vec\n            self.print_message('Created Song embeddings')\n            self.save_bert()\n            return vec\n    \n    def save_bert(self):\n        \"\"\"\n        Save BERT vectors.\n        \"\"\"\n        bert_name = f'{self.model_name}_Song_embeddings_preprocessed_sentences' if self.model_name else 'Song_embeddings_preprocessed_sentences'\n        save_vectors(bert_name, self.vec['BERT'], self.data_file_name)\n        self.print_message('Saved Song embeddings')\n\n    def get_lda_bert_vectors(self):\n        \"\"\"\n        Get LDA and BERT vector representations.\n        \"\"\"\n        self.get_lda_vectors()\n        self.get_bert_vectors()\n        return self.vec['LDA'], self.vec['BERT']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:15.974248Z","iopub.execute_input":"2024-11-11T06:35:15.974666Z","iopub.status.idle":"2024-11-11T06:35:16.031175Z","shell.execute_reply.started":"2024-11-11T06:35:15.974622Z","shell.execute_reply":"2024-11-11T06:35:16.029915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdvancedSongRecommender:\n    def __init__(self, latent_representations: np.ndarray, reduced_dim_latent_representations: np.ndarray, song_lyrics: List[str], top_k: int = 50, cache_dir_in=song_recommender_cache_input_path, cache_dir_out=song_recommender_cache_out_path):\n        \"\"\"\n        Initialize the recommender with latent representations and lyrics data.\n\n        Parameters:\n        - latent_representations: Latent representations of songs.\n        - song_lyrics: List of lyrics corresponding to each song.\n        - top_k: Number of top recommendations to return.\n        - cache_dir_in: Directory where cache files will be read from.\n        - cache_dir_out: Directory where cache files will be saved.\n        \"\"\"\n        self.latent_representations = latent_representations\n        self.reduced_dim_latent_representations = reduced_dim_latent_representations\n        self.song_lyrics = song_lyrics\n        self.top_k = top_k\n        self.index_file_in = f\"{cache_dir_in}/faiss_index.idx\"\n        self.cluster_file_in = f\"{cache_dir_in}/cluster_labels.npy\"\n        self.index_file_out = f\"{cache_dir_out}/faiss_index.idx\"\n        self.cluster_file_out = f\"{cache_dir_out}/cluster_labels.npy\"\n        self.theme_cache_file_in = f\"{cache_dir_in}/cluster_themes.pkl\"\n        self.theme_cache_file_out = f\"{cache_dir_out}/cluster_themes.pkl\"\n\n        print(\"Building FAISS index for global candidate retrieval\")\n        # Step 1: FAISS Index for Global Candidate Retrieval\n        self.faiss_index = self._build_faiss_index()\n        \n        print(\"Building HDBSCAN clusters\")\n        # Step 2: HDBSCAN Global Clustering (precomputed for theme clusters)\n        self.cluster_labels = self._build_hdbscan_clusters()\n        \n        print(\"Storing songs in each cluster for fast retrieval\")\n        # Store songs in each cluster for fast retrieval\n        self.cluster_members = self._create_cluster_members()\n\n        # print(\"Building Gensim LDA model for theme extraction\")\n        # # Step 3: Build Gensim LDA model for theme extraction\n        # self.lda_model, self.dictionary = self._train_gensim_lda_model()\n\n        # print(\"Precomputing and caching cluster themes\")\n        # # Step 4: Precompute and cache cluster themes during initialization\n        # self.theme_cache = self._precompute_and_cache_themes()\n\n    def _build_faiss_index(self):\n        \"\"\"Build or load a FAISS index with optimized parameters for a large dataset.\"\"\"\n        if not self._load_faiss_index():  # Load existing index if available\n            d = self.latent_representations.shape[1]\n            nlist = 4096  # Number of Voronoi cells\n            m = 16  # Number of sub-quantizers for PQ\n            index = faiss.IndexIVFPQ(faiss.IndexFlatIP(d), d, nlist, m, 8)  # 8 bits per sub-vector\n            index.train(self.latent_representations)\n            index.add(self.latent_representations)\n            index.nprobe = 20  # Number of clusters to search during querying\n            faiss.write_index(index, self.index_file_out)  # Save for future use\n            print(\"FAISS index built and saved.\")\n        return index\n\n    def _load_faiss_index(self):\n        \"\"\"Load the FAISS index if it exists.\"\"\"\n        try:\n            self.faiss_index = faiss.read_index(self.index_file_in)\n            print(\"FAISS index loaded from disk.\")\n            return True\n        except:\n            print(\"No pre-existing FAISS index found; building a new one.\")\n            return False\n\n    def _build_hdbscan_clusters(self):\n        \"\"\"Build or load HDBSCAN clustering model.\"\"\"\n        if not self._load_clusters():\n            hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=1000, min_samples=100, metric='euclidean')\n            cluster_labels = hdbscan_clusterer.fit_predict(self.reduced_dim_latent_representations)\n            np.save(self.cluster_file_out, cluster_labels)  # Save cluster labels for future use\n            print(\"HDBSCAN clustering done and saved.\")\n        return cluster_labels\n\n    def _load_clusters(self):\n        \"\"\"Load precomputed cluster labels if available.\"\"\"\n        try:\n            self.cluster_labels = np.load(self.cluster_file_in)\n            print(\"Cluster labels loaded from disk.\")\n            return True\n        except:\n            print(\"No pre-existing cluster labels found; building clusters.\")\n            return False\n\n    def _create_cluster_members(self) -> Dict[int, List[int]]:\n        \"\"\"Organize songs into clusters for fast cluster-based retrieval.\"\"\"\n        cluster_dict = {}\n        for idx, label in enumerate(self.cluster_labels):\n            if label != -1:  # Ignore noise points\n                cluster_dict.setdefault(label, []).append(idx)\n        return cluster_dict\n\n    def _train_gensim_lda_model(self) -> tuple:\n        \"\"\"Train a Gensim LDA model to extract topics/themes from song lyrics.\"\"\"\n        # Tokenize the lyrics (simple whitespace tokenizer)\n        texts = [song.split() for song in self.song_lyrics]\n        \n        # Create a dictionary and corpus for Gensim LDA model\n        dictionary = Dictionary(texts)\n        corpus = [dictionary.doc2bow(text) for text in texts]\n\n        # Train the LDA model with 10 topics\n        lda_model = LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)\n        print(\"Gensim LDA model trained for theme extraction.\")\n        return lda_model, dictionary\n\n    def _precompute_and_cache_themes(self) -> Dict[int, str]:\n        \"\"\"Precompute and cache the themes for all clusters during initialization.\"\"\"\n        theme_cache = self._load_theme_cache()\n        if theme_cache:\n            return theme_cache\n        else:\n            theme_cache = {}\n            for cluster_id in set(self.cluster_labels):\n                if cluster_id != -1:  # Exclude noise points\n                    theme_cache[cluster_id] = self._get_cluster_theme(cluster_id)\n            # Save the cached themes to disk for later use\n            self._save_theme_cache(theme_cache)\n            print(\"Cluster themes precomputed and cached.\")\n            return theme_cache\n    \n    def _load_theme_cache(self):\n        \"\"\"Load precomputed cluster themes if available.\"\"\"\n        if os.path.exists(self.theme_cache_file_in):\n            with open(self.theme_cache_file_in, 'rb') as f:\n                theme_cache = pickle.load(f)\n            print(\"Cluster themes loaded from disk.\")\n            return theme_cache\n        else:\n            print(\"No pre-existing cluster themes found; building clusters.\")\n            return None\n\n    def _get_cluster_theme(self, cluster_id: int) -> str:\n        \"\"\"Generate a theme summary for a given cluster using Gensim LDA model.\"\"\"\n        cluster_songs = self.cluster_members.get(cluster_id, [])\n        lyrics_for_cluster = [self.song_lyrics[song_id] for song_id in cluster_songs]\n\n        # Tokenize the songs' lyrics for LDA analysis\n        texts_for_cluster = [song.split() for song in lyrics_for_cluster]\n        corpus_for_cluster = [self.dictionary.doc2bow(text) for text in texts_for_cluster]\n\n        # Get the topics distribution for the cluster's songs\n        topic_distribution = self.lda_model[corpus_for_cluster]\n\n        # Collect the most frequent terms for the top topics\n        top_topics = [max(doc, key=lambda x: x[1])[0] for doc in topic_distribution]\n        topic_keywords = []\n        for topic_idx in top_topics:\n            keywords = [word for word, _ in self.lda_model.show_topic(topic_idx, topn=5)]\n            topic_keywords.append(\", \".join(keywords))\n\n        # Summarize the theme of the cluster\n        theme_summary = \" | \".join(topic_keywords)\n        return theme_summary\n\n    def _save_theme_cache(self, theme_cache: Dict[int, str]):\n        \"\"\"Save the theme cache to disk.\"\"\"\n        with open(self.theme_cache_file_out, 'wb') as f:\n            pickle.dump(theme_cache, f)\n        print(\"Theme cache saved.\")\n\n    def recommend(self, song_id: int, novelty: float = 0.5) -> List[int]:\n        \"\"\"\n        Generate recommendations with adjustable novelty using FAISS and cluster-based filtering.\n\n        Parameters:\n        - song_id: ID of the song to base recommendations on.\n        - novelty: Control the diversity (0 = similar songs, 1 = diverse songs).\n\n        Returns:\n        - List of recommended song IDs with theme explanation.\n        \"\"\"\n        print(\"Starting recommendations for song_id %d\", song_id)\n\n        # Step 1: Retrieve top-k global candidates from FAISS\n        _, top_candidates = self.faiss_index.search(self.latent_representations[song_id:song_id+1], self.top_k)\n        # candidate_reps = self.latent_representations[top_candidates.flatten()]\n        \n        # Step 2: Cluster-Based Filtering\n        target_cluster = self.cluster_labels[song_id]\n        main_cluster_songs = self.cluster_members.get(target_cluster, [])\n        \n        # Adjust clusters based on novelty\n        if novelty < 0.5:\n            # Low novelty: Prioritize songs within main cluster\n            filtered_candidates = [song for song in top_candidates.flatten() if song in main_cluster_songs]\n        else:\n            # High novelty: Include songs from neighboring clusters\n            nearby_clusters = self._get_nearby_clusters(target_cluster, novelty)\n            filtered_candidates = [song for song in top_candidates.flatten() if song in nearby_clusters]\n\n        # Step 3: Intra-Cluster Ranking (Cosine similarity)\n        scores = cosine_similarity(\n            self.reduced_dim_latent_representations[song_id:song_id+1],\n            self.reduced_dim_latent_representations[filtered_candidates]\n        ).flatten()\n        ranked_candidates = [filtered_candidates[i] for i in np.argsort(scores)]\n\n        # Step 4: Get Themes and Explanation\n        theme_explanations = []\n        for song in ranked_candidates:\n            theme = self._get_cluster_theme(self.cluster_labels[song])\n            theme_explanations.append(theme)\n\n        return ranked_candidates[:self.top_k], theme_explanations\n\n    def _get_nearby_clusters(self, target_cluster: int, novelty_factor: float = 0.5) -> List[int]:\n        \"\"\"Get nearby clusters based on centroids' distances (simulate diverse recommendations).\"\"\"\n        cluster_distances = {\n            label: np.linalg.norm(\n                np.mean(self.reduced_dim_latent_representations[self.cluster_members[label]], axis=0) -\n                np.mean(self.reduced_dim_latent_representations[self.cluster_members[target_cluster]], axis=0)\n            )\n            for label in self.cluster_members\n        }\n        sorted_clusters = sorted(cluster_distances.items(), key=lambda x: x[1])\n        \n        # Adjust number of clusters included based on novelty\n        max_clusters = int(len(sorted_clusters) * novelty_factor)\n        return [label for label, _ in sorted_clusters[:max_clusters]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:16.033159Z","iopub.execute_input":"2024-11-11T06:35:16.033617Z","iopub.status.idle":"2024-11-11T06:35:16.078525Z","shell.execute_reply.started":"2024-11-11T06:35:16.033566Z","shell.execute_reply":"2024-11-11T06:35:16.077357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PREPROCESS DATA","metadata":{}},{"cell_type":"code","source":"# if not load_existing_preprocessed_data:\n#     print('Getting lyrics')\n#     data = documents #pd.read_csv(working_files_path + '/train.csv')\n#     data = data.fillna('')  # only the comments has NaN's\n#     rws = data.lyrics\n#     print(type(rws))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:16.080007Z","iopub.execute_input":"2024-11-11T06:35:16.080436Z","iopub.status.idle":"2024-11-11T06:35:16.094714Z","shell.execute_reply.started":"2024-11-11T06:35:16.080387Z","shell.execute_reply":"2024-11-11T06:35:16.093684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sentences, token_lists, idx_in = load_progress()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:16.096353Z","iopub.execute_input":"2024-11-11T06:35:16.097175Z","iopub.status.idle":"2024-11-11T06:35:16.106309Z","shell.execute_reply.started":"2024-11-11T06:35:16.097122Z","shell.execute_reply":"2024-11-11T06:35:16.105339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# if load_existing_preprocessed_data:\n#     sentences, token_lists = load_preprocessed_files(data_file_name)\n# else:\n#     sentences, token_lists, idx_in = preprocess(rws)\n# print(type(sentences), type(token_lists))\n# # print(np.shape(sentences), np.shape(token_lists))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:16.107753Z","iopub.execute_input":"2024-11-11T06:35:16.108158Z","iopub.status.idle":"2024-11-11T06:35:16.117609Z","shell.execute_reply.started":"2024-11-11T06:35:16.108118Z","shell.execute_reply":"2024-11-11T06:35:16.116375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if load_preprocessed_checkpoints:\n    print('Loading preprocessed train checkpoints')\n    train_sentences, train_token_lists, train_idx_in, train_ngram_token_lists = load_progress()\n    print('Loaded preprocessed train checkpoints')\n    print(len(train_idx_in), len(train_sentences), len(train_token_lists))\nelse:\n    print('Enable load_preprocessed_checkpoints')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:16.119221Z","iopub.execute_input":"2024-11-11T06:35:16.119629Z","iopub.status.idle":"2024-11-11T06:35:38.580819Z","shell.execute_reply.started":"2024-11-11T06:35:16.119589Z","shell.execute_reply":"2024-11-11T06:35:38.577391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reduce_dim_umap(latent_representations, n_components=30):\n    # Initialize UMAP model\n    umap_model = umap.UMAP(n_components=n_components, metric='euclidean')\n\n    # Fit UMAP on the entire dataset\n    final_embeddings = umap_model.fit_transform(latent_representations)\n\n    # Save the final embeddings\n    np.save(\"final_reduced_dim_latent_representations.npy\", final_embeddings)\n    \n    return final_embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:38.595342Z","iopub.execute_input":"2024-11-11T06:35:38.596967Z","iopub.status.idle":"2024-11-11T06:35:38.617822Z","shell.execute_reply.started":"2024-11-11T06:35:38.596891Z","shell.execute_reply":"2024-11-11T06:35:38.614401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if load_existing_model:\n    tm = load_latest_topic_model(num_topics = ntopic, gamma = gamma)\nelse:\n    # Define the topic model object\n    #tm = TopicModel(k = 10), method = TFIDF)\n    # tm = TopicModel(k = ntopic, gamma = gamma, eps = db_scan_eps, min_samp = db_scan_min_samples, data_file_name = 'data_file_name')\n    # Fit the topic model by chosen method\n    # tm.vectorize_tfidf(sentences, max_df = 0.5)\n    \n    # tm = TopicModel(\n    #     data_file_name = data_file_name,\n    #     token_lists = train_ngram_token_lists,\n    #     sentences = train_sentences\n    # )\n    # tm.get_lda_bert_vectors()\n    # tm.evaluate_lda_model()\n    # tm.get_lda_vectors()\n    # tm.tune_lda_hyperparameters()\n    \n\n    print('Loading preprocessed val checkpoints')\n    val_sentences, val_token_lists, val_idx_in, val_ngram_token_lists = load_progress(val_checkpoints_input_path)\n    print('Loaded preprocessed val checkpoints')\n    tm_val = TopicModel(\n        data_file_name = data_file_name,\n        token_lists = val_token_lists,\n        sentences = val_sentences,\n        model_name = 'val',\n        tfidf_input_path = val_tfidf_input_path,\n        lda_vec_input_path = val_lda_input_path,\n        bert_input_path = val_song_embeddings_input_path,\n    )\n    tm_val.get_lda_vectors()\n    \n    # tm.vectorize_tfidf_2(token_lists)\n    # tm.load_tfidf()\n    # vec_lda = tm.get_lda_vectors()\n    # save_vectors('LDA', vec_lda, tm.data_file_name)\n    # print('LDA vectors saved')\n\n    # vec_bert = tm.get_bert_vectors(sentences)\n    # save_vectors('BERT_preprocessed_sentences', vec_bert, tm.data_file_name)\n    # print('BERT vectors saved')\n    # vec_lda = load_vectors_from_path(lda_input_path)\n    # song_embeddings = load_vectors_from_path(song_embeddings_input_path)\n    # autoencoder_handler = AutoencoderHandler(vec_lda, song_embeddings, scaled = False, latent_dim=64, num_epochs=24, batch_size=64, checkpoint_dir=autoencoder_checkpoint_dir, log_interval=100, data_file_name=data_file_name)\n    # autoencoder_handler.train()\n\n    # latent_representations = load_vectors_from_path(latent_representations_input_path)\n    # reduced_dim_latent_representations = reduce_dim_umap(latent_representations)\n    # lyrics = load_vectors_from_path(reordered_lyrics_input_path)\n    # recommender = AdvancedSongRecommender(latent_representations, reduced_dim_latent_representations, lyrics)\n    # recommendations = recommender.recommend(song_id=10, novelty=0.6)\n    # logging.info(\"Recommended songs for song_id 10: %s\", recommendations)\n\n    # Assume unseen_song_rep is the latent representation of a new song\n    # unseen_song_rep = np.random.rand(64)\n    # recommendations, theme_explanations = recommender.recommend_for_unseen_song(unseen_song_rep, novelty=0.6)\n    # logging.info(\"Recommended songs for unseen song: %s\", recommendations)\n    # logging.info(\"Theme explanations: %s\", theme_explanations)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:35:38.624690Z","iopub.execute_input":"2024-11-11T06:35:38.626139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('done')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}